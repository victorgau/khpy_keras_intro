# 【唯客學院微課程】Keras使用簡介

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/victorgau/khpy_keras_intro/)

主要是講 Keras 的 Sequential API 的使用，不含 Functional API 的部份。內含 CNN, RNN 等應用。

### 課程內容：

* Fully Connected Networks
* CNN
* RNN/LSTM/GRU

### 相關連結：

* [Keras](https://keras.io/)
* [TensorFlow](https://www.tensorflow.org/)

### 資料集：

* [scikit-learn datasets](https://scikit-learn.org/stable/datasets/index.html)
* [keras datasets](https://keras.io/api/datasets/)
* [UC Irvine Machine Learning Repositories](https://archive.ics.uci.edu/ml/index.php)
* [ImageNet](http://www.image-net.org/)
* [COCO Dataset](http://cocodataset.org/)
* [CIFAR Dataset](https://www.cs.toronto.edu/~kriz/cifar.html)

### 相關教學：

* [台大李弘毅教授 YouTube](https://www.youtube.com/channel/UC2ggjtuuWvxrHHHiaDH1dlQ)
* [政大蔡炎龍教授 Moocs](http://moocs.nccu.edu.tw/course/172/intro)
* [開源機器人技術(教學影片)](https://tw.openrobot.org/dir/index?sn=1090)
* [莫煩Python](https://morvanzhou.github.io/)
* [CS231n: Convolutional Neural Networks for Visual Recognition](http://cs231n.stanford.edu/)
* [Tensorflow Tutorials](https://github.com/Hvass-Labs/TensorFlow-Tutorials)

### 其他：

* [Unofficial Windows Binaries for Python Extension Packages](https://www.lfd.uci.edu/~gohlke/pythonlibs/)
* [Gradient Descent](https://en.wikipedia.org/wiki/Gradient_descent)
* [Stochastic Gradient Descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent)

### 論文連結：

* [arxiv.org](https://arxiv.org/)

### Dropout:

* [Improving neural networks by preventing co-adaptation of feature detectors](https://arxiv.org/abs/1207.0580)
* [Dropout: A simple way to prevent neural networks from overfitting](https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf)
* [Improving neural networks with dropout](http://www.cs.toronto.edu/~nitish/msc_thesis.pdf)
* [Dropout as data augmentation](https://arxiv.org/abs/1506.08700)

### CNN:

* [LeNet](http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf)
* [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)
* [VGGNet](https://arxiv.org/pdf/1409.1556.pdf)
* [GoogleNet](https://arxiv.org/pdf/1409.4842.pdf)
* [ResNet](https://arxiv.org/pdf/1512.03385.pdf)
* [ResNet v2](https://arxiv.org/pdf/1603.05027.pdf)

### Object Detection: 

* [R-CNN](https://arxiv.org/abs/1311.2524)
* [Fast R-CNN](https://arxiv.org/abs/1504.08083)
* [Faster R-CNN](https://arxiv.org/abs/1506.01497)
* [Mask R-CNN](https://arxiv.org/abs/1703.06870)
* [YOLO v1](https://arxiv.org/abs/1506.02640)
* [YOLO v2](https://arxiv.org/abs/1612.08242v1)
* [YOLO v3](https://arxiv.org/abs/1804.02767)
* [SSD](https://arxiv.org/abs/1512.02325)

### RNN:

* [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)
* [LSTM](https://arxiv.org/pdf/1402.1128.pdf)
* [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)
* [LSTM vs GRU](https://arxiv.org/pdf/1412.3555.pdf)

### NLP:

* [Attention is all you need](https://arxiv.org/pdf/1706.03762.pdf)
* [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473)
* [Effective Approaches to Attention-based Neural Machine Translation](https://arxiv.org/abs/1508.04025)
